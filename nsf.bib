@article{Kraljic2006,
abstract = {Lexical context strongly influences listeners' identification of ambiguous sounds. For example, a sound midway between /f/ and /s/ is reported as /f/ in "sheri\_," but as /s/ in "Pari\_." Norris, McQueen, and Cutler (2003) have demonstrated that after hearing such lexically determined phonemes, listeners expand their phonemic categories to include more ambiguous tokens than before. We tested whether listeners adjust their phonemic categories for a specific speaker. Do listeners learn a particular speaker's "accent"? Similarly, we examined whether perceptual learning is specific to the particular ambiguous phonemes that listeners hear, or whether the adjustments generalize to related sounds. Participants heard ambiguous /d/ or /t/ phonemes during a lexical decision task. They then categorized sounds on /d/-/t/ and /b/-/p/ continua, either in the same voice that they had heard for lexical decision, or in a different voice. Perceptual learning generalized across both speaker and test continua: Changes in perceptual representations are robust and broadly tuned.},
author = {Kraljic, Tanya and Samuel, Arthur G},
file = {:Users/dkleinschmidt/Documents/papers/Kraljic, Samuel - Generalization in perceptual learning for speech. - 2006.pdf:pdf},
issn = {1069-9384},
journal = {Psychonomic bulletin \& review},
keywords = {Decision Making,Generalization (Psychology),Humans,Learning,Speech Perception,Vocabulary},
month = apr,
number = {2},
pages = {262--8},
pmid = {16892992},
title = {{Generalization in perceptual learning for speech.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16892992},
volume = {13},
year = {2006}
}
@inproceedings{Kleinschmidt2010,
author = {Kleinschmidt, Dave},
booktitle = {poster presented at the 2nd Annual Neurobiology of Language Conference},
file = {:Users/dkleinschmidt/Documents/papers/Kleinschmidt - Efficient coding of speech in the auditory cortex - 2010.pdf:pdf},
title = {{Efficient coding of speech in the auditory cortex}},
year = {2010}
}
@article{Hillenbrand1995,
abstract = {The purpose of this study was to replicate and extend the classic study of vowel acoustics by Peterson and Barney (PB) [J. Acoust. Soc. Am. 24, 175-184 (1952)]. Recordings were made of 45 men, 48 women, and 46 children producing the vowels /i,I,e, epsilon,ae,a, [symbol: see text],O,U,u, lambda,3 iota/ in h-V-d syllables. Formant contours for F1-F4 were measured from LPC spectra using a custom interactive editing tool. For comparison with the PB data, formant patterns were sampled at a time that was judged by visual inspection to be maximally steady. Analysis of the formant data shows numerous differences between the present data and those of PB, both in terms of average frequencies of F1 and F2, and the degree of overlap among adjacent vowels. As with the original study, listening tests showed that the signals were nearly always identified as the vowel intended by the talker. Discriminant analysis showed that the vowels were more poorly separated than the PB data based on a static sample of the formant pattern. However, the vowels can be separated with a high degree of accuracy if duration and spectral change information is included.},
author = {Hillenbrand, J and Getty, L A and Clark, M J and Wheeler, K},
file = {:Users/dkleinschmidt/Documents/papers/Hillenbrand et al. - Acoustic characteristics of American English vowels. - 1995.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Adult,Child,Female,Humans,Male,Phonetics,Speech Acoustics},
month = may,
number = {5.1},
pages = {3099--111},
pmid = {7759650},
title = {{Acoustic characteristics of American English vowels.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7759650},
volume = {97},
year = {1995}
}
@inproceedings{Toscano2008,
author = {Toscano, Joseph C and McMurray, Bob},
booktitle = {Proceedings of the 30th Annual Conference of the Cognitive Science Society},
file = {:Users/dkleinschmidt/Documents/papers/Toscano, McMurray - Using the distributional statistics of speech sounds for weighting and integrating acoustic cues - 2008.pdf:pdf},
keywords = {cue integration,mixture,of gaussians,speech development,speech perception,statistical learning},
pages = {433--438},
title = {{Using the distributional statistics of speech sounds for weighting and integrating acoustic cues}},
url = {http://csjarchive.cogsci.rpi.edu/Proceedings/2008/pdfs/p433.pdf},
year = {2008}
}
@article{McMurray2009,
abstract = {Recent evidence (Maye, Werker \& Gerken, 2002) suggests that statistical learning may be an important mechanism for the acquisition of phonetic categories in the infant's native language. We examined the sufficiency of this hypothesis and its implications for development by implementing a statistical learning mechanism in a computational model based on a mixture of Gaussians (MOG) architecture. Statistical learning alone was found to be insufficient for phonetic category learning--an additional competition mechanism was required in order for the categories in the input to be successfully learnt. When competition was added to the MOG architecture, this class of models successfully accounted for developmental enhancement and loss of sensitivity to phonetic contrasts. Moreover, the MOG with competition model was used to explore a potentially important distributional property of early speech categories--sparseness--in which portions of the space between phonetic categories are unmapped. Sparseness was found in all successful models and quickly emerged during development even when the initial parameters favoured continuous representations with no gaps. The implications of these models for phonetic category learning in infants are discussed.},
author = {McMurray, Bob and Aslin, Richard N and Toscano, Joseph C},
doi = {10.1111/j.1467-7687.2009.00822.x},
file = {:Users/dkleinschmidt/Documents/papers/McMurray, Aslin, Toscano - Statistical learning of phonetic categories insights from a computational approach. - 2009.pdf:pdf},
issn = {1467-7687},
journal = {Developmental science},
keywords = {Algorithms,Computational Biology,Computational Biology: methods,Humans,Infant,Language Development,Learning,Models, Psychological,Normal Distribution,Phonetics,Statistics as Topic},
month = apr,
number = {3},
pages = {369--78},
pmid = {19371359},
title = {{Statistical learning of phonetic categories: insights from a computational approach.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2742678\&tool=pmcentrez\&rendertype=abstract},
volume = {12},
year = {2009}
}
@article{McMurray2008,
abstract = {Speech perception requires listeners to integrate multiple cues that each contribute to judgments about a phonetic category. Classic studies of trading relations assessed the weights attached to each cue but did not explore the time course of cue integration. Here, we provide the first direct evidence that asynchronous cues to voicing (/b/ vs. /p/) and manner (/b/ vs. /w/) contrasts become available to the listener at different times during spoken word recognition. Using the visual world paradigm, we show that the probability of eye movements to pictures of target and of competitor objects diverge at different points in time after the onset of the target word. These points of divergence correspond to the availability of early (voice onset time or formant transition slope) and late (vowel length) cues to voicing and manner contrasts. These results support a model of cue integration in which phonetic cues are used for lexical access as soon as they are available.},
author = {McMurray, Bob and Clayards, Meghan A and Tanenhaus, Michael K and Aslin, Richard N},
doi = {10.3758/PBR.15.6.1064},
file = {:Users/dkleinschmidt/Documents/papers/McMurray et al. - Tracking the time course of phonetic cue integration during spoken word recognition. - 2008(2).pdf:pdf},
issn = {1069-9384},
journal = {Psychonomic bulletin \& review},
keywords = {Attention,Cues,Humans,Judgment,Pattern Recognition,Phonetics,Speech Acoustics,Speech Perception,Visual},
month = dec,
number = {6},
pages = {1064--71},
pmid = {19001568},
title = {{Tracking the time course of phonetic cue integration during spoken word recognition.}},
url = {http://pbr.psychonomic-journals.org/cgi/content/abstract/15/6/1064},
volume = {15},
year = {2008}
}
@article{Bejjanki,
author = {Bejjanki, Vikranth Rao and Clayards, Meghan and Knill, David C and Aslin, Richard N},
file = {:Users/dkleinschmidt/Documents/papers/Bejjanki et al. - Cue integration in categorical tasks Insights from audio-visual speech perception - Unknown.pdf:pdf},
title = {{Cue integration in categorical tasks: Insights from audio-visual speech perception}}
}
@article{Maye2002,
abstract = {For nearly two decades it has been known that infants' perception of speech sounds is affected by native language input during the first year of life. However, definitive evidence of a mechanism to explain these developmental changes in speech perception has remained elusive. The present study provides the first evidence for such a mechanism, showing that the statistical distribution of phonetic variation in the speech signal influences whether 6- and 8-month-old infants discriminate a pair of speech sounds. We familiarized infants with speech sounds from a phonetic continuum, exhibiting either a bimodal or unimodal frequency distribution. During the test phase, only infants in the bimodal condition discriminated tokens from the endpoints of the continuum. These results demonstrate that infants are sensitive to the statistical distribution of speech sounds in the input language, and that this sensitivity influences speech perception.},
author = {Maye, Jessica and Werker, Janet F and Gerken, LouAnn},
file = {:Users/dkleinschmidt/Documents/papers/Maye, Werker, Gerken - Infant sensitivity to distributional information can affect phonetic discrimination. - 2002.pdf:pdf},
issn = {0010-0277},
journal = {Cognition},
keywords = {Attention,Female,Humans,Infant,Language Development,Male,Mental Recall,Phonetics,Psycholinguistics,Speech Perception},
month = jan,
number = {3},
pages = {B101--11},
pmid = {11747867},
title = {{Infant sensitivity to distributional information can affect phonetic discrimination.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11747867},
volume = {82},
year = {2002}
}
@article{Olshausen1996,
abstract = {The receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs.},
author = {Olshausen, B A and Field, David J},
doi = {10.1038/381607a0},
file = {:Users/dkleinschmidt/Documents/papers/Olshausen, Field - Emergence of simple-cell receptive field properties by learning a sparse code for natural images. - 1996.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
keywords = {Algorithms,Learning,Models,Neurological,Neurons,Neurons: physiology,Ocular,Ocular: physiology,Vision,Visual Cortex,Visual Cortex: cytology,Visual Cortex: physiology},
month = jun,
number = {6583},
pages = {607--9},
pmid = {8637596},
title = {{Emergence of simple-cell receptive field properties by learning a sparse code for natural images.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/8637596},
volume = {381},
year = {1996}
}
@article{Simon2007,
abstract = {Neurons in primary auditory cortex (AI) in the ferret (Mustela putorius) that are well described by their spectrotemporal response field (STRF) are found also to have a distinctive property that we call temporal symmetry. For temporally symmetric neurons, every temporal cross-section of the STRF (impulse response) is given by the same function of time, except for a scaling and a Hilbert rotation. This property held in 85\% of neurons (123 out of 145) recorded from awake animals and in 96\% of neurons (70 out of 73) recorded from anesthetized animals. This property of temporal symmetry is highly constraining for possible models of functional neural connectivity within and into AI. We find that the simplest models of functional thalamic input, from the ventral medial geniculate body (MGB), into the entry layers of AI are ruled out because they are incompatible with the constraints of the observed temporal symmetry. This is also the case for the simplest models of functional intracortical connectivity. Plausible models that do generate temporal symmetry, from both thalamic and intracortical inputs, are presented. In particular, we propose that two specific characteristics of the thalamocortical interface may be responsible. The first is a temporal mismatch between the fast dynamics of the thalamus and the slow responses of the cortex. The second is that all thalamic inputs into a cortical module (or a cluster of cells) must be restricted to one point of entry (or one cell in the cluster). This latter property implies a lack of correlated horizontal interactions across cortical modules during the STRF measurements. The implications of these insights in the auditory system, and comparisons with similar properties in the visual system, are explored.},
author = {Simon, Jonathan Z and Depireux, Didier a and Klein, David J and Fritz, Jonathan B and Shamma, Shihab a},
doi = {10.1162/neco.2007.19.3.583},
file = {:Users/dkleinschmidt/Documents/papers/Simon et al. - Temporal symmetry in primary auditory cortex implications for cortical connectivity. - 2007(2).pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Acoustic Stimulation,Acoustic Stimulation: methods,Animals,Auditory Cortex,Auditory Cortex: cytology,Auditory Cortex: physiology,Auditory Pathways,Auditory Pathways: physiology,Brain Mapping,Computer Simulation,Ferrets,Models, Neurological,Nerve Net,Nerve Net: physiology,Neural Networks (Computer),Neurons,Neurons: physiology,Spectrum Analysis,Vision, Ocular,Vision, Ocular: physiology},
month = mar,
number = {3},
pages = {583--638},
pmid = {17298227},
title = {{Temporal symmetry in primary auditory cortex: implications for cortical connectivity.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/17298227},
volume = {19},
year = {2007}
}
