\documentclass[12pt]{article}

\input{nsf_preamble.tex}


\begin{document}
PREVIOUS RESEARCH EXPERIENCE

I have a wealth of research experience, which has both whetted my appetite for more and also substantially humbled me.  I know that research is not only rewarding and exciting but also challenging, and I have a appreciation of the difficulty of formulating research questions that are both interesting and tractable.  As an undergraduate at Williams College, I worked with Safa Zaki on the cognitive psychology of categorization, and also did a Cognitive Science honors thesis, on computational modeling of speech perception.  As a Baggett Fellow at the University of Maryland, I worked on Bayesian models of unsupervised learning of phonetic categories, and

%[MAYBE LATER?] My previous experience has prepared me very well to take advantage of the exciting, collaborative, and interdisciplinary environment at the University of Rochester, and in the few short months that I've been here ... [TRAILS OFF]


%Previous research experience
%-- Safa - categorization, modeling, hands-on experience, skepticism
%My interest in cognitive science began early in my undergraduate education.  In my first semester of college I took a philosophy course on metaphysics and epistemology.  Deciding that that was not for me, my second semester I took an introductory course on interdisciplinary cognitive science, and that was that.  Halfway through the semester, I asked the instructor (who, ironically, was the same instructor I had taken metaphysics and epistemology with the previous semester) how I could get involved with cognitive science research.  He put me in touch with Safa Zaki, who agreed to hire me as a research assistant for the summer.  I continued working in Dr. Zaki's lab until I graduated, and was intimately involved in every aspect the projects we worked on together.  

Having had my interest in cognitive science piqued early, I was put in touch with Dr. Zaki in the spring of 2006.  I worked in her lab starting that summer, and continued until I graduated in 2009.  We worked closely together to conceptualize and design studies, and I had primary responsibility for implementing and running.  I also was responsible for the implementation and application of non-standard computational models for analyzing the data we collected.  We're currently writing up two of these projects for publication.

The first of these was an investigation of the source of apparent dissociation between simple, easily-verbalizable categorization tasks and more complicated tasks that require the integration of information from multiple stimulus dimensions for optimal performance.  Dissociations between these tasks have been used to argue for the existence of multiple, functionally and neurally distinct categorization systems, but there the particular study we were investigating had confounded type of task with different types of difficulty.  With Dr. Zaki, I designed, ran, and analyzed data from a study which removed the dissociation by removing one of these confounds, and we're currently preparing this manuscript for submission.  

The second project we worked on, which is still ongoing, was on the role of transformational knowledge on categorization.  Previous work has shown that subjects are sensitive to coherent transformations associated with categories, and that presenting the same category exemplars in random order vs. as a coherent transformation changes subject's categorization judgements about novel test stimuli.  As currently formulated, most modern models of categorization do not predict and cannot account for these results.  We designed, ran, and analyzed a study which replicated and extended this work, and are currently investigating modeling frameworks which may be able to explain our results.  


%   I worked with Dr. Zaki from that summer (2006) until I graduated in 2009.  That first summer I spent reading up on models of categorization, both from exemplar theorists as well as multiple-systems theorists (who have proposed that different types of categorization tasks are handled by functionally- and neurally-disociable sub-systems).


%-- thesis - (bob port?) difficulties of modeling!
%   The Tyng Scholarship (the merit scholarship I received at Williams) supports one summer of independent research, so in the summer of 2008, I visited Indiana University to study phonetics with Bob Port in the linguistics department.  Our free-wheeling conversations (and arguments) about the basic nature of phonetic categories deeply influenced my understanding of the basic problem of speech perception.  More practically, he introduced me to a vast body of literature on the issue, both behavioral and computational, and was instrumental in helping me formulate the topic of my undergraduate thesis.
%   My thesis project addressed a peculiar set of data, which shows that having high phonotactic probability (lots of common sound sequences) slows processing of words, but speeds processing of pseudo-words.  One explanation for this phenomenon 

%%% FROM GRAD APP SOP...
The other major component of my undergraduate research experience was my Cognitive Science honors thesis, which I formulated with the help of Robert Port at Indiana over the summer of 2008, supported by the Tyng Scholarship (the competitive merit scholarship I received from Williams).
Based on analysis of neural network models, this project argued in favor of a role for sublexical representations in the processing of spoken words and nonwords.  Vitevitch and Luce (1999) found that, while phonotactic probability and lexical neighborhood density (LND) strongly covary, they have opposite effects on the processing of words and nonwords: high phonotactic probability facilitates the processing of nonwords, while high LND inhibits the processing of words.  They propose a modeling account which incorporates phonotactic probability and LND effects through different functional pathways that are nevertheless the result of a single learning algorithm.  Critically, in this account, phonotactic probability effects on nonword processing are mediated by relatively large sublexical items (e.g., biphones or syllables) that have the same representational status as lexical items.  While the suitability of this model in this case can be interpreted as indirect evidence for a role for large sublexical representations in speech perception, this argument is undermined by the considerable flexibility of the model.  However, by comparing the a priori qualitative range of behavior of models incorporating different representational schemes, I showed that removing the sublexical representations from the model causes it to behave, in general, in a way that is inconsistent with human performance, lending strength to the case for sublexical representations.

%%% NEEDS TO BE TIGHTENED UP!
This project required that I independently implement a number of different models, which required configuring a large number of parameters by hand in order to get reasonable performance on the task I was modeling.  I thus have first-hand knowledge of how frustrating and technically challenging a modeling project can be, not to mention the conceptual difficulties that come with linking modeling results to behavioral ones, but also how rewarding it is to bring such a large and complicated project to completion.  I also learned how important it is to get input from non-specialists, since Dr. Zaki, who advised the project, is not intimately familiar with either the behavioral paradigm or the model I used, and consequently pushed me to clearly explain the larger context and justification for the project.

% the question of whether representations of an intermediate size---between minimal units such as phonemes and actual words---were required to explain the interaction between lexicality (whether a target is an actual word or not) and effects of phonotactic probability/neighborhood density.  Using a modeling framework widely held to be a behaviorally and neurally plausible model of lexical access (Adaptive Resonance Theory, or ART), I implemented models with and without minimal- and intermediate-level representations ("phonemes" and "biphones").  By using techniques of global model comparison (where an uninformative prior over the models parameters is used to determine the range of qualitative data patterns that the model is capable of producing), I determined that removing intermediate-level representations rendered the model incapable of producing the qualitative data pattern observed in human subjects for non-words.
%-- UMD - computational neuroscience, phonetics/phonology/linguistics, bayesian modeling
%   I took advantage of the significant latitude afforded me as a Baggett Fellow to educate myself on modern statistical methods for data analysis and the modeling of cognitive processes.  I was involved in starting a project with Bill Idsardi, Ewan Dunbar, and Naomi Feldman to further evaluate and extend a hierarchical model of distributional learning of phonetic and lexical categories.
%   Bill and I were excited about the prospects of using unsupervised methods from the machine learning literature to model phonetic categorization, and he pointed me to a paper where sparse coding was used for art authentication[***].  We decided to apply a similar model to audition, which led to work (guided and as well by Dan Butts and Jonathan Simon) on modeling neural receptive fields in primary auditory cortex[***]. ...

At the University of Maryland, as a Baggett Fellow in the Linguistics department, I was involved, to varying degrees, in a wide variety of projects.  I ran subjects in an MEG study of the difference between the perception of certain musical intervals embedded in speech and non-speech sounds, and I designed software to automate the pre-processing of video stimuli for a study on the effect on sign-language intelligibility of reversing small, local segments of videos, while preserving the global ordering of these segments.  I also worked with Jordan Boyd-Graber on the development of a hierarchical Bayesian model which segments a string of phonetic segments in order to learn words and phonetic categories.

My main project was the development of a sparse-coding model of how the primary auditory cortex might be adapted to the statistics of natural sounds, including speech.  Sparse coding is a technique that, like principal component analysis (PCA), finds an optimal linear transformation between an uninformative way of representing stimuli to a more informative way.  In the example of visual images, each image can be represented by a vector, where each dimension represents the brightness of one image pixel.  However, considering a large set of images, the brightness of one pixel is highly dependent on the brightness of neighboring pixels, and so there is redundancy in this representation.  Linear statistical models remove this redundancy by finding a set of components (which can also be represented as images), such that each original image is represented by the weighted sum of components.  Sparse coding finds the set of components that maximizes the \emph{sparseness} of these sums, or minimizes the number of components that are used to represent each individual image.  As it turns out, the sparse components of natural images are indistinguishable from the receptive fields of single neurons in primary visual cortex (V1).  Each V1 unit's receptive field describes that unit's preferred stimulus, whose presence best predicts a spike by that neuron.



%As a Baggett Fellow in the UMD Linguistics department, I had a large amount of freedom to explore topics of interest.  I assisted with an MEG study on musical interval perception by running subjects, and I helped prepare stimuli for a study on sign language.  I attended a wide variety of lab meetings, audited courses in psycholinguistics and computational neuroscience, and read as much of the literature related to statistical models of phonetic category learning as I could.  Out of this grew the project which is the first part of my Research Plan here.

%This project was motivated by the desire to ground phonetic category learning in neurally plausible representations of sounds.  Bill and I had read a paper on using sparse coding (SC) for art authentication, and this led me to the larger literature on SC.  Sparse coding attempts to find a set of underlying components so that each input (e.g. a small image patch) can be represented as a weighted sum of components as efficiently as possible.  For sparse coding, an efficient representation is one where each input is represented using as few components as possible (so most components are ``turned off'', making the distribution of component activations sparse).  What makes SC plausible as a model of perceptual representations is that when sparse coding is applied to a large set natural images, the components it extracts are essentially the same as the receptive fields of primary visual cortex neurons.

%I also actively participated in the language science IGERT program there, in two ways.  First, [[[Winter Storm]]].  Second, [[[ferrets]]]
%[[[ ^^ this may be better in the personal statement, yes I think definitely better in the personal statement ]]]



\end{document}